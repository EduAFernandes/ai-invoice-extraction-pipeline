# LLM Provider Configuration
LLM_PRIMARY_PROVIDER=openai
LLM_ENABLE_FALLBACK=true
LLM_FALLBACK_ORDER=gemini,openai,anthropic

# OpenAI
OPENAI_API_KEY=sk-proj-your_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=1500

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-your_key_here
ANTHROPIC_MODEL=claude-3-haiku-20240307
ANTHROPIC_TEMPERATURE=0.1
ANTHROPIC_MAX_TOKENS=1500

# Google Gemini
GEMINI_API_KEY=AIza_your_key_here
GEMINI_MODEL=gemini-1.5-flash
GEMINI_TEMPERATURE=0.1
GEMINI_MAX_TOKENS=1500

# Ollama (Local)
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.2:latest

# MinIO/S3 Storage
MINIO_ENDPOINT=http://minio:9000
MINIO_ACCESS_KEY=admin
MINIO_SECRET_KEY=password123
MINIO_BUCKET_NAME=invoices
MINIO_INCOMING_PREFIX=incoming/
MINIO_PROCESSED_PREFIX=processed/
MINIO_FAILED_PREFIX=failed/

# PostgreSQL Database
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=invoice_db
POSTGRES_USER=invoice_user
POSTGRES_PASSWORD=secure_password

# Langfuse Observability
LANGFUSE_PUBLIC_KEY=pk_your_key_here
LANGFUSE_SECRET_KEY=sk_your_key_here
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_ENABLED=true

# Processing Configuration
BATCH_SIZE=5
MAX_RETRIES=3
RETRY_DELAY_SECONDS=15
ENABLE_CACHING=true
CACHE_TTL_HOURS=24
MAX_ACTIVE_RUNS=3

# Quality Thresholds
CONFIDENCE_THRESHOLD=0.85
AUTO_REVIEW_QUEUE_ENABLED=true

# Alerting
PAGERDUTY_API_KEY=
ALERT_EMAIL=

# Environment
AIRFLOW_ENV=development
